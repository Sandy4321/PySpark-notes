{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haciendo features a partir de un dataset con Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los features o caracteristicas son representaciones numericas que caracterizan atributos de un conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features categoricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_file = sc.textFile('/Users/user/GitHub/PySpark-Notes/ml-100k/u.user')\n",
    "#text_file.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#df_2 = sqlContext.read.format('com.databricks.spark.csv').options(header='false', delimiter='|').load('/Users/user/GitHub/PySpark-Notes/ml-100k/u.user')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id       movie_title release_date  video_release_date  \\\n",
      "0         1  Toy Story (1995)  01-Jan-1995                 NaN   \n",
      "1         2  GoldenEye (1995)  01-Jan-1995                 NaN   \n",
      "\n",
      "                                            IMDb-URL  unknown  Action  \\\n",
      "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
      "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
      "\n",
      "   Adventure  Animation  Childrens   ...     Fantasy  Film-Noir  Horror  \\\n",
      "0          0          1          1   ...           0          0       0   \n",
      "1          1          0          0   ...           0          0       0   \n",
      "\n",
      "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0        0        0        0       0         0    0        0  \n",
      "1        0        0        0       0         1    0        0  \n",
      "\n",
      "[2 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_3 = pd.read_csv('/Users/user/GitHub/PySpark-Notes/ml-100k/u.item', \\\n",
    "                   sep = '|',names = ['movie_id','movie_title','release_date', \\\n",
    "                                      'video_release_date', 'IMDb-URL','unknown','Action','Adventure',\\\n",
    "                                      'Animation', 'Childrens','Comedy','Crime','Documentary'\\\n",
    "                                      ,'Drama','Fantasy','Film-Noir','Horror','Musical','Mystery',\\\n",
    "                                      'Romance','Sci-Fi','Thriller', 'War' ,'Western'],encoding='iso-8859-1')\n",
    "print df_3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De la columna que nos interesa, regresamos las diferentes ocupaciones y los pasamos a una lista:\n",
      "\n",
      "['administrator', 'artist', 'doctor', 'educator', 'engineer', 'entertainment', 'executive', 'healthcare', 'homemaker', 'lawyer', 'librarian', 'marketing', 'none', 'other', 'programmer', 'retired', 'salesman', 'scientist', 'student', 'technician', 'writer']\n",
      "\n",
      "llave para 'administrator': 0\n",
      "llave para 'artist': 1\n",
      "llave para 'doctor': 2\n",
      "llave para 'educator': 3\n",
      "llave para 'engineer': 4\n",
      "llave para 'entertainment': 5\n",
      "llave para 'executive': 6\n",
      "llave para 'healthcare': 7\n",
      "llave para 'homemaker': 8\n",
      "llave para 'lawyer': 9\n",
      "llave para 'librarian': 10\n",
      "llave para 'marketing': 11\n",
      "llave para 'none': 13\n",
      "llave para 'programmer': 14\n",
      "llave para 'retired': 15\n",
      "llave para 'salesman': 16\n",
      "llave para 'scientist': 17\n",
      "llave para 'technician': 19\n",
      "llave para 'writer': 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/user/GitHub/PySpark-Notes/ml-100k/u.user', sep='|',\n",
    "                 #Le podemos colocar algunos headers para mayor comodidad:\n",
    "                 names = ['Age','Gender', 'Occupation', 'ZIP_CODE'])\n",
    "\n",
    "# De la columna que nos interesa, regresamos las diferentes ocupaciones y los pasamos a una lista:\n",
    "all_occupations = sorted(df['Occupation'].unique().tolist())\n",
    "print 'De la columna que nos interesa, regresamos las diferentes ocupaciones y los pasamos a una lista:\\n\\n',all_occupations\n",
    "\n",
    "idx = 0\n",
    "all_occupations_dict = {}\n",
    "\n",
    "for occupations in all_occupations:\n",
    "    all_occupations_dict[occupations] = idx\n",
    "    idx +=1\n",
    "    \n",
    "#Ahora generamos una representación numerica para cada tipo de ocupación:    \n",
    "print \"\\nllave para 'administrator': %d\" % all_occupations_dict['administrator']\n",
    "print \"llave para 'artist': %d\" % all_occupations_dict['artist']\n",
    "print \"llave para 'doctor': %d\" % all_occupations_dict['doctor']\n",
    "print \"llave para 'educator': %d\" % all_occupations_dict['educator']\n",
    "print \"llave para 'engineer': %d\" % all_occupations_dict['engineer']\n",
    "print \"llave para 'entertainment': %d\" % all_occupations_dict['entertainment']\n",
    "print \"llave para 'executive': %d\" % all_occupations_dict['executive']\n",
    "print \"llave para 'healthcare': %d\" % all_occupations_dict['healthcare']\n",
    "print \"llave para 'homemaker': %d\" % all_occupations_dict['homemaker']\n",
    "print \"llave para 'lawyer': %d\" % all_occupations_dict['lawyer']\n",
    "print \"llave para 'librarian': %d\" % all_occupations_dict['librarian']\n",
    "print \"llave para 'marketing': %d\" % all_occupations_dict['marketing']\n",
    "print \"llave para 'none': %d\" % all_occupations_dict['other']\n",
    "print \"llave para 'programmer': %d\" % all_occupations_dict['programmer']\n",
    "print \"llave para 'retired': %d\" % all_occupations_dict['retired']\n",
    "print \"llave para 'salesman': %d\" % all_occupations_dict['salesman']\n",
    "print \"llave para 'scientist': %d\" % all_occupations_dict['scientist']\n",
    "print \"llave para 'technician': %d\" % all_occupations_dict['technician']\n",
    "print \"llave para 'writer': %d\" % all_occupations_dict['writer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary feature vector (administrator): \n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (administrator) 21\n",
      "Binary feature vector (artist): \n",
      "[ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (artist)21\n",
      "Binary feature vector (doctor): \n",
      "[ 1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (doctor)21\n",
      "Binary feature vector (educator): \n",
      "[ 1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (educator)21\n",
      "Binary feature vector (engineer): \n",
      "[ 1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (engineer)21\n",
      "Binary feature vector (entertainment): \n",
      "[ 1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (entertainment)21\n",
      "Binary feature vector (executive): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (executive)21\n",
      "Binary feature vector (healthcare): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (healthcare)21\n",
      "Binary feature vector (homemaker): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (homemaker)21\n",
      "Binary feature vector (lawyer): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (lawyer)21\n",
      "Binary feature vector (librarian): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (librarian)21\n",
      "Binary feature vector (marketing): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (marketing)21\n",
      "Binary feature vector (none): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (none)21\n",
      "Binary feature vector (programmer): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (programmer)21\n",
      "Binary feature vector (retired): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (retired)21\n",
      "Binary feature vector (salesman): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (salesman)21\n",
      "Binary feature vector (scientist): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.\n",
      "  0.  0.  0.]\n",
      "\n",
      "Dimension del vector (scientist)21\n",
      "Binary feature vector (technician): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.\n",
      "  0.  1.  0.]\n",
      "\n",
      "Dimension del vector (technician)21\n",
      "Binary feature vector (writer): \n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.\n",
      "  0.  1.  1.]\n",
      "\n",
      "Dimension del vector (writer)21\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#prefiero usar shape pero con len se puede\n",
    "k = len(all_occupations_dict)\n",
    "binary_x = np.zeros(k)\n",
    "\n",
    "\n",
    "k_administrator = all_occupations_dict['administrator']\n",
    "binary_x[k_administrator] = 1\n",
    "print 'Binary feature vector (administrator): \\n', binary_x\n",
    "print '\\nDimension del vector (administrator) %d'% binary_x.shape\n",
    "\n",
    "###################################################\n",
    "k_artist = all_occupations_dict['artist']\n",
    "binary_x[k_artist] = 1\n",
    "print 'Binary feature vector (artist): \\n', binary_x\n",
    "print '\\nDimension del vector (artist)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_doctor = all_occupations_dict['doctor']\n",
    "binary_x[k_doctor] = 1\n",
    "print 'Binary feature vector (doctor): \\n', binary_x\n",
    "print '\\nDimension del vector (doctor)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['educator']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (educator): \\n', binary_x\n",
    "print '\\nDimension del vector (educator)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['engineer']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (engineer): \\n', binary_x\n",
    "print '\\nDimension del vector (engineer)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['entertainment']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (entertainment): \\n', binary_x\n",
    "print '\\nDimension del vector (entertainment)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['executive']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (executive): \\n', binary_x\n",
    "print '\\nDimension del vector (executive)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['healthcare']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (healthcare): \\n', binary_x\n",
    "print '\\nDimension del vector (healthcare)%d'% binary_x.shape\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['homemaker']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (homemaker): \\n', binary_x\n",
    "print '\\nDimension del vector (homemaker)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['lawyer']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (lawyer): \\n', binary_x\n",
    "print '\\nDimension del vector (lawyer)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['librarian']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (librarian): \\n', binary_x\n",
    "print '\\nDimension del vector (librarian)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['marketing']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (marketing): \\n', binary_x\n",
    "print '\\nDimension del vector (marketing)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['none']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (none): \\n', binary_x\n",
    "print '\\nDimension del vector (none)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['programmer']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (programmer): \\n', binary_x\n",
    "print '\\nDimension del vector (programmer)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['retired']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (retired): \\n', binary_x\n",
    "print '\\nDimension del vector (retired)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['salesman']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (salesman): \\n', binary_x\n",
    "print '\\nDimension del vector (salesman)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['scientist']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (scientist): \\n', binary_x\n",
    "print '\\nDimension del vector (scientist)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['technician']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (technician): \\n', binary_x\n",
    "print '\\nDimension del vector (technician)%d'% binary_x.shape\n",
    "\n",
    "\n",
    "###################################################\n",
    "k_programmer = all_occupations_dict['writer']\n",
    "binary_x[k_programmer] = 1\n",
    "print 'Binary feature vector (writer): \\n', binary_x\n",
    "print '\\nDimension del vector (writer)%d'% binary_x.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ToDo: ahora pegamos los vectores en una sola matriz:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>time_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  time_stamp\n",
       "0      196      242       3   881250949\n",
       "1      186      302       3   891717742\n",
       "2       22      377       1   878887116\n",
       "3      244       51       2   880606923\n",
       "4      166      346       1   886397596"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_df= pd.read_csv('/Users/user/GitHub/PySpark-Notes/ml-100k/u.data'\\\n",
    "                       ,sep = '\t', names= ['user_id', 'item_id','rating', 'time_stamp'])\n",
    "user_data_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_stamps = user_data_df['time_stamp'].tolist()\n",
    "#print time_stamps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamps PythonRDD[4] at RDD at PythonRDD.scala:43\n",
      "hour_of_day PythonRDD[5] at RDD at PythonRDD.scala:43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9, 13, 1, 23, 23]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_data_raw = sc.textFile('/Users/user/GitHub/PySpark-Notes/ml-100k/u.data')\n",
    "rating_data = rating_data_raw.map(lambda line: line.split(\"\\t\"))\n",
    "\n",
    "\n",
    "def extract_datetime(ts):\n",
    "    import datetime\n",
    "    return datetime.datetime.fromtimestamp(ts)\n",
    "    \n",
    "timestamps = rating_data.map(lambda fields: int(fields[3]))\n",
    "print 'timestamps', timestamps\n",
    "hour_of_day = timestamps.map(lambda ts: extract_datetime(ts).hour)\n",
    "print 'hour_of_day', hour_of_day\n",
    "hour_of_day.take(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Toy Story (1995)\n",
      "1     GoldenEye (1995)\n",
      "2    Four Rooms (1995)\n",
      "3    Get Shorty (1995)\n",
      "4       Copycat (1995)\n",
      "Name: movie_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_3['movie_title'] = df_3['movie_title'].astype('O')\n",
    "print df_3['movie_title'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Toy Story\n",
      "1     GoldenEye\n",
      "2    Four Rooms\n",
      "3    Get Shorty\n",
      "4       Copycat\n",
      "Name: titles, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# el problema es que tambien quita los numeros de los titulos de las peliculas\n",
    "df_3['titles'] = df_3['movie_title'].str.extract('([a-zA-Z ]+)', expand=False).str.strip()\n",
    "print df_3['titles'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Toy Story\n",
      "1     GoldenEye\n",
      "2    Four Rooms\n",
      "3    Get Shorty\n",
      "4       Copycat\n",
      "Name: titles1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_3['titles1'] = df_3['movie_title'].str.split('(', 1).str[0].str.strip()\n",
    "print df_3['titles1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Toy Story\n",
      "1     GoldenEye\n",
      "2    Four Rooms\n",
      "3    Get Shorty\n",
      "4       Copycat\n",
      "Name: titles2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_3['titles2'] = df_3['movie_title'].str.replace(r'\\([^)]*\\)', '').str.strip()\n",
    "print df_3['titles2'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1682, 2217)\n"
     ]
    }
   ],
   "source": [
    "#Con BOW de scikit\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(df_3['titles2'])\n",
    "#y = df['label'].values\n",
    "\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can not infer schema for type: <type 'unicode'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5b4f568caa21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'titles2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mspDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.1/libexec/python/pyspark/sql/context.pyc\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mjrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerDeUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoJavaArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_java_object_rdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssql_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplySchemaToPythonRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.1/libexec/python/pyspark/sql/context.pyc\u001b[0m in \u001b[0;36m_createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchemaFromList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.1/libexec/python/pyspark/sql/context.pyc\u001b[0m in \u001b[0;36m_inferSchemaFromList\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    209\u001b[0m             warnings.warn(\"inferring schema from dict is deprecated,\"\n\u001b[1;32m    210\u001b[0m                           \"please use pyspark.sql.Row instead\")\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_has_nulltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.1/libexec/python/pyspark/sql/types.pyc\u001b[0m in \u001b[0;36m_infer_schema\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not infer schema for type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_infer_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not infer schema for type: <type 'unicode'>"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "spDF = sqlContext.createDataFrame(df_3['titles2'])\n",
    "spDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data should be an RDD of list of string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7180922b3e77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'titles2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msynonyms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindSynonyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'china'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.1/libexec/python/pyspark/mllib/feature.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \"\"\"\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data should be an RDD of list of string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         jmodel = callMLlibFunc(\"trainWord2VecModel\", data, int(self.vectorSize),\n\u001b[1;32m    577\u001b[0m                                \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumPartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: data should be an RDD of list of string"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.feature import Word2Vec\n",
    "#inp = sc.textFile(\"text8_lines\").map(lambda row: row.split(\" \"))\n",
    "\n",
    "\n",
    "\n",
    "word2vec = Word2Vec()\n",
    "model = word2vec.fit(df_3['titles2'])\n",
    "\n",
    "synonyms = model.findSynonyms('china', 40)\n",
    "\n",
    "for word, cosine_distance in synonyms:\n",
    "    print \"{}: {}\".format(word, cosine_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
